{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /---------------------------------------------------------------\n",
    "# Course            : Big Data Analytics\n",
    "# Course Code       : CDB3034\n",
    "# Assignment        : 2\n",
    "# Group             : 1\n",
    "# Student Name 1    : Chan Seow Fen / 0207368\n",
    "# Student Name 2    : Cheah Pin Chee / 0197637\n",
    "# Student Name 3    : Ong Yi Wen / 0207333\n",
    "# Student Name 4    : Saw Keat Loon / 0207778\n",
    "# /---------------------------------------------------------------\n",
    "# Data source: https://openlearning.uowmkdu.edu.my/courses/pg-cbd-3034n-big-data-analysis-jjoshua/data_a2/?cl=1\n",
    "# Original Data Files: T_Data_C1.csv, T_Data_C2.csv, T_Data_C3.csv\n",
    "# /---------------------------------------------------------------\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import Imputer, StringIndexer, VectorAssembler, OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "default_file_store_path = \"dbfs:/FileStore/\"\n",
    "\n",
    "# Task 2: Customer Retention Prediction and Display Results\n",
    "# Load the cleaned data\n",
    "df_final = spark.read.csv(\"dbfs:/FileStore/tables/BDA_T_data_Final.csv\", header=True, inferSchema=True)\n",
    "# Drop same customer ID\n",
    "df_final = df_final.dropDuplicates(subset=[\"CustomerID\"])\n",
    "print(\"Data size of BDA_T_data_Merged.csv: \", df_final.count(), \" rows\", \" and \", len(df_final.columns), \" columns\")\n",
    "display(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.1 Find the number of churn users are in the dataset, discuss your opinion on the output whether the given dataset is balanced or imbalanced. What will be the descriptive statistics for tenure, totalcharges, and monthly charges?\n",
    "\n",
    "# Find the total user, churn user, and no churn user in the dataset\n",
    "total_user = df_final.count()\n",
    "churn_count = df_final.filter(col(\"Churn\") == \"Yes\").count()\n",
    "no_churn_count = df_final.filter(col(\"Churn\") == \"No\").count()\n",
    "print(\"Total number of users in the dataset     : \", total_user)\n",
    "print(\"Number of churn users in the dataset     : \", churn_count)\n",
    "print(\"Number of no churn users in the dataset  : \", no_churn_count)\n",
    "\n",
    "# Calculate ratio\n",
    "churn_ratio = churn_count / total_user * 100\n",
    "no_churn_ratio = no_churn_count / total_user * 100\n",
    "\n",
    "\n",
    "# Plot pie chart with value labeled to visualize the churn ratio with matplotlib\n",
    "labels = 'Churn', 'No Churn'\n",
    "sizes = [churn_count, no_churn_count]\n",
    "colors = ['royalblue', 'lightcoral']\n",
    "explode = (0.1, 0)  # explode 1st slice\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct=lambda pct: f\"{pct:.1f}%\\n({int(pct/100 * sum(sizes)):.0f})\", startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.title(\"Churn Ratio\")\n",
    "plt.show()\n",
    "\n",
    "# Descriptive statistics for tenure, totalcharges, and monthly charges\n",
    "df_final.describe([\"tenure\", \"TotalCharges\", \"MonthlyCharges\"]).display()\n",
    "\n",
    "# Insight with histogram for each feature and visualize the distribution of tenure, totalcharges, and monthly charges\n",
    "# For Tenure\n",
    "tenure = df_final.select(\"tenure\").rdd.flatMap(lambda x: x).collect()\n",
    "counts, bins, patches = plt.hist(tenure, bins=30, color='royalblue', edgecolor='white', linewidth=0.2)\n",
    "plt.title(\"Tenure Distribution\")\n",
    "plt.xlabel(\"Tenure\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "# Display the count for each bin\n",
    "for count, bin in zip(counts, bins):\n",
    "    plt.text(bin, count, str(int(count)), fontsize=8, color='black', weight='bold')\n",
    "plt.show()\n",
    "# For TotalCharges\n",
    "totalcharges = df_final.select(\"TotalCharges\").rdd.flatMap(lambda x: x).collect()\n",
    "counts, bins, patches = plt.hist(totalcharges, bins=30, color='royalblue', edgecolor='white', linewidth=0.2)\n",
    "plt.title(\"TotalCharges Distribution\")\n",
    "plt.xlabel(\"TotalCharges\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "# Display the count for each bin\n",
    "for count, bin in zip(counts, bins):\n",
    "    plt.text(bin, count, str(int(count)), fontsize=8, color='black', weight='bold')\n",
    "plt.show()\n",
    "# For MonthlyCharges\n",
    "monthlycharges = df_final.select(\"MonthlyCharges\").rdd.flatMap(lambda x: x).collect()\n",
    "counts, bins, patches = plt.hist(monthlycharges, bins=30, color='royalblue', edgecolor='white', linewidth=0.2)\n",
    "plt.title(\"MonthlyCharges Distribution\")\n",
    "plt.xlabel(\"MonthlyCharges\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "# Display the count for each bin\n",
    "for count, bin in zip(counts, bins):\n",
    "    plt.text(bin, count, str(int(count)), fontsize=8, color='black', weight='bold')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.2 Do the analysis on a) Male, Female, churn, and b) SeniorCitizen, churn out of the two which is the most suitable attribute that you can keep for further analysis? Does the tenure correlate to people become churn? Pivot the values and plot the values for better representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.3\tUse a model building process with Databricks for the given data, create a suitable training, evaluation data items, then build a pipeline with suitable transformers (onehotencoder, stringindexer, vectorassembler)\n",
    "spark_dr = spark_dr.drop(\"customerID\")\n",
    "\n",
    "spark_dr = spark_dr.withColumn(\"tenure\", col(\"tenure\").cast(\"double\")).withColumn(\"MonthlyCharges\", col(\"MonthlyCharges\").cast(\"double\")).withColumn(\"TotalCharges\", col(\"TotalCharges\").cast(\"double\"))\n",
    "\n",
    "imputer = Imputer(inputCols=[\"TotalCharges\"], outputCols=[\"TotalCharges\"], strategy=\"mean\")  # Or \"median\"\n",
    "\n",
    "spark_dr = imputer.fit(spark_dr).transform(spark_dr)\n",
    "trainDF, testDF = spark_dr.randomSplit([0.8, 0.2], seed=42)\n",
    "print(trainDF.cache().count())  # Cache because accessing training data multiple times\n",
    "print(testDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.4\tManipulate the feature engineering, using the transformers Imputer, StringIndexer, QuantileDiscretizer. Use VectorAssembler to give input to the model, you may take note, to use suitable numerical columns to end the feature engineering stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.5\tCombine the pipeline fit, configure the train, test data and apply suitable regression model for the label and features columns. Execute the model and print the results of accuracy, plot the output with Area Under ROC. Evaluate the model with Binaryclassifiermetrics to analyze the prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
